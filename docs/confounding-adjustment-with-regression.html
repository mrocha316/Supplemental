<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Confounding adjustment with regression | Causality and Multiple Regression Supplement</title>
  <meta name="description" content="This is a supplement for MA206 Probability and Statistics, West Point, NY." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Confounding adjustment with regression | Causality and Multiple Regression Supplement" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a supplement for MA206 Probability and Statistics, West Point, NY." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Confounding adjustment with regression | Causality and Multiple Regression Supplement" />
  
  <meta name="twitter:description" content="This is a supplement for MA206 Probability and Statistics, West Point, NY." />
  

<meta name="author" content="Krista Watts and Kevin Cummiskey" />


<meta name="date" content="2021-10-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="causality.html"/>
<link rel="next" href="interactions.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intro Stats Supplement</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#goals-of-quantitative-research-describe-predict-cause-and-effect"><i class="fa fa-check"></i><b>1.1</b> Goals of quantitative research (describe, predict, cause-and-effect)</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#validity"><i class="fa fa-check"></i><b>1.2</b> Validity</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>2</b> Causality</a>
<ul>
<li class="chapter" data-level="2.1" data-path="causality.html"><a href="causality.html#what-does-it-mean-for-one-thing-to-cause-another"><i class="fa fa-check"></i><b>2.1</b> What does it mean for one thing to cause another</a></li>
<li class="chapter" data-level="2.2" data-path="causality.html"><a href="causality.html#randomized-controlled-experiments"><i class="fa fa-check"></i><b>2.2</b> Randomized controlled experiments</a></li>
<li class="chapter" data-level="2.3" data-path="causality.html"><a href="causality.html#observational-studies-and-confounding"><i class="fa fa-check"></i><b>2.3</b> Observational Studies and Confounding</a></li>
<li class="chapter" data-level="2.4" data-path="causality.html"><a href="causality.html#causal-diagrams"><i class="fa fa-check"></i><b>2.4</b> Causal Diagrams</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="causality.html"><a href="causality.html#confounding-variable"><i class="fa fa-check"></i><b>2.4.1</b> Confounding variable</a></li>
<li class="chapter" data-level="2.4.2" data-path="causality.html"><a href="causality.html#collider"><i class="fa fa-check"></i><b>2.4.2</b> Collider</a></li>
<li class="chapter" data-level="2.4.3" data-path="causality.html"><a href="causality.html#mediator"><i class="fa fa-check"></i><b>2.4.3</b> Mediator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html"><i class="fa fa-check"></i><b>3</b> Confounding adjustment with regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#categorical-confounding-variable"><i class="fa fa-check"></i><b>3.1</b> Categorical confounding variable</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#unadjusted-effect-of-x-on-y"><i class="fa fa-check"></i><b>3.1.1</b> Unadjusted effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="3.1.2" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#effect-of-x-on-y-adjusting-for-c"><i class="fa fa-check"></i><b>3.1.2</b> Effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> adjusting for <span class="math inline">\(C\)</span></a></li>
<li class="chapter" data-level="3.1.3" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#assessing-model-adequacy"><i class="fa fa-check"></i><b>3.1.3</b> Assessing model adequacy</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#quantitative-explanatory-variable-with-quantitative-confounding-variable"><i class="fa fa-check"></i><b>3.2</b> Quantitative explanatory variable with quantitative confounding variable</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#unadjusted-effect-of-x-on-y-1"><i class="fa fa-check"></i><b>3.2.1</b> Unadjusted effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="3.2.2" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#effect-of-x-on-y-adjusting-for-c-1"><i class="fa fa-check"></i><b>3.2.2</b> Effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> adjusting for <span class="math inline">\(C\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="confounding-adjustment-with-regression.html"><a href="confounding-adjustment-with-regression.html#assessing-model-adequacy-1"><i class="fa fa-check"></i><b>3.2.3</b> Assessing model adequacy</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>4</b> Interactions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="interactions.html"><a href="interactions.html#main-effect-of-house-size-on-sales-price"><i class="fa fa-check"></i><b>4.1</b> Main effect of house size on sales price</a></li>
<li class="chapter" data-level="4.2" data-path="interactions.html"><a href="interactions.html#interaction-between-house-size-and-location"><i class="fa fa-check"></i><b>4.2</b> Interaction between house size and location</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="activity.html"><a href="activity.html"><i class="fa fa-check"></i><b>5</b> Activity</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Causality and Multiple Regression Supplement</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="confounding-adjustment-with-regression" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Confounding adjustment with regression</h1>
<p>Recall from Chapter 2 that confounding occurs when the treatment variable depends upon another variable that is itself a cause of the outcome. When researchers have not controlled for a confounding variable through study design, they employ statistical methods during analysis to adjust for confounding. One of the most common techniques is multiple regression.</p>
<div id="categorical-confounding-variable" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Categorical confounding variable</h2>
<p>Let’s say we have treatment variable (X) and response variable (Y) but the relationship between them is confounded by a third variable (C). For instance, suppose we want to investigate the relationship between ice cream sales and hospital admissions for heart attacks in the summer in NYC. In this example, our “treatment” is volume of ice cream sales on any given day in NYC and our response is number of hospital admissions that day for heart attacks. If we only look at those two variables, we might see a strong correlation; as ice cream sales increase, so do heart attacks. But it would be a mistake to infer that eating ice cream causes heart attacks from this analysis alone.</p>
<p>What does it mean for ice cream sales to <em>cause</em> heart attacks? How is that different from an association between ice cream sales and heart attacks? Ice cream sales cause heart attacks if high and low ice cream sales on the same days resulted in different heart attack rates. However, we only get to observe each day with one value of ice cream sales. Therefore, a third variable may be a common cause of both ice cream sales and heart attacks. In this case, we say there is an association between ice cream sales and heart attacks.</p>
<p>In our case, the third variable is temperature. People tend to buy more ice cream when it is hot; if there also tends to be more heart attacks when it is hot, temperature confounds the relationship between ice cream sales and hospital admissions for heart attack. Recall the confounding diagram from Chapter 2. <!--![ A confounding variable $C$ on the effect of $X$ on $Y$.](./images/confounder.png)--> If we extend it to this example, we have</p>
<div class="figure">
<img src="images/ice_cream_graph.png" alt="" />
<p class="caption">Causal diagram for ice cream sales and heart attacks.</p>
</div>
<p>Notice that we believe that a change in temperature <em>causes</em> a change in both ice cream sales and heart attacks.</p>
<p>If we control for temperature, then we will no longer see an association between ice cream sales and heart attacks. One way to control for temperature is to restrict the analysis to only days in a very narrow temperature range. However, restricting your analysis in this way would result in a lot of lost information. Instead, we turn to statistical methods like regression.</p>
<div id="unadjusted-effect-of-x-on-y" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Unadjusted effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span></h3>
<p>There exists a belief that height is protective against high blood pressure; that is, taller people tend to have lower blood pressure. In this section, we investigate this belief using data gathered from 1999 to 2006 by the CDC’s National Health and Nutrition Examination Survey (NHANES), a (relatively) representative sample of the adult U.S. population. The data contains variables on 12,671 Americans age 18 and older who were not pregnant or taking high blood pressure medication. We are interested in estimating the effect of height (HT) on mean systolic blood pressure (SBP). We could model this with the following regression equation.
<span class="math display">\[\widehat{SBP}=\beta_0+\beta_1*HT\]</span></p>
<p>If we fit a regression model with height as the treatment variable and systolic blood pressure as the response, we get the following results:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="confounding-adjustment-with-regression.html#cb1-1" aria-hidden="true" tabindex="-1"></a>bp_dat<span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;./data/blood_pressure.csv&quot;</span>)</span>
<span id="cb1-2"><a href="confounding-adjustment-with-regression.html#cb1-2" aria-hidden="true" tabindex="-1"></a>ht_mod<span class="ot">=</span><span class="fu">lm</span>(SBP<span class="sc">~</span>HT,</span>
<span id="cb1-3"><a href="confounding-adjustment-with-regression.html#cb1-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> bp_dat)</span>
<span id="cb1-4"><a href="confounding-adjustment-with-regression.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ht_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SBP ~ HT, data = bp_dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -52.876 -13.804  -3.703   9.922 141.605 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 141.22705    2.52887  55.846  &lt; 2e-16 ***
## HT           -0.10276    0.01504  -6.833 8.58e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 20.09 on 17486 degrees of freedom
## Multiple R-squared:  0.002663,   Adjusted R-squared:  0.002606 
## F-statistic: 46.69 on 1 and 17486 DF,  p-value: 8.575e-12</code></pre>
<p>Note the coefficient on height is negative, meaning that taller people actually tend to have lower blood pressure! In fact, we expect SBP to go down by about .103 mmHG for every cm in additional height. This makes sense when we look at the data. There is A LOT of data here, but we see a general decrease in SBP as height increases.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="confounding-adjustment-with-regression.html#cb3-1" aria-hidden="true" tabindex="-1"></a>bp_dat<span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="confounding-adjustment-with-regression.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="st">`</span><span class="at">HT</span><span class="st">`</span>,</span>
<span id="cb3-3"><a href="confounding-adjustment-with-regression.html#cb3-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y=</span><span class="st">`</span><span class="at">SBP</span><span class="st">`</span>))<span class="sc">+</span></span>
<span id="cb3-4"><a href="confounding-adjustment-with-regression.html#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb3-5"><a href="confounding-adjustment-with-regression.html#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>This is matches to what we expected. So I guess our work is done. Wait – not so fast. Biological sex is a potential confounder.</p>
</div>
<div id="effect-of-x-on-y-adjusting-for-c" class="section level3" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> adjusting for <span class="math inline">\(C\)</span></h3>
<p>Men tend to be taller than women (175 cm vs 162cm). Men also tend to have higher mean systolic blood pressure (122 vs 118 mmHG). Therefore, Sex is a possible confounder. Below is our data, colored by Sex.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="confounding-adjustment-with-regression.html#cb4-1" aria-hidden="true" tabindex="-1"></a>bp_dat<span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="confounding-adjustment-with-regression.html#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="st">`</span><span class="at">HT</span><span class="st">`</span>,</span>
<span id="cb4-3"><a href="confounding-adjustment-with-regression.html#cb4-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y=</span><span class="st">`</span><span class="at">SBP</span><span class="st">`</span>))<span class="sc">+</span></span>
<span id="cb4-4"><a href="confounding-adjustment-with-regression.html#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">colour =</span> SEX))<span class="sc">+</span></span>
<span id="cb4-5"><a href="confounding-adjustment-with-regression.html#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Here, we see SBP tends to decrease as height increases <em>within men</em>. Likewise, <em>within women</em>, we see the same. If we want to estimate the effect of height on blood pressure, we must first adjust for Sex. We do this using multiple regression. “Multiple” because we have multiple variables on the right hand side of the equation. (This could be multiple explanatory variables or, as we have here a single explanatory variable with one or more confounding variables.) Often we do this simply by adding the other variable to the regression equation. But how do we add a categorical variable to a mathematical equation. Suppose my regression model is</p>
<p><span class="math display">\[\widehat{SBP}=\beta_0+\beta_1*HT+\beta_2*SEX\]</span></p>
<p>What does it mean to multiply something by “male?” When we want to include categorical variables as explanatory variables in regression models, we often use indicator (also called ‘dummy’) variables. In this case, biological sex has two levels, male and female, and we need one indicator variable to represent Sex. We will let our indicator variable equal 1 if a subject was male and 0 if the subject was female. <span class="math inline">\(\beta_2\)</span> is interpreted as the expected increase in SBP when a subject is male.</p>
<p>A possible multiple regression equation with SBP as our response, height as the treatment adjusting for Sex as a confounder is</p>
<p><span class="math display">\[\widehat{SBP}=\beta_0+\beta_1*HT+\beta_2*SEX\]</span></p>
<p>When we add Sex to the model, we get the following results.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="confounding-adjustment-with-regression.html#cb5-1" aria-hidden="true" tabindex="-1"></a>ht_gen_mod<span class="ot">=</span><span class="fu">lm</span>(SBP<span class="sc">~</span>HT<span class="sc">+</span>SEX,</span>
<span id="cb5-2"><a href="confounding-adjustment-with-regression.html#cb5-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> bp_dat)</span>
<span id="cb5-3"><a href="confounding-adjustment-with-regression.html#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ht_gen_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SBP ~ HT + SEX, data = bp_dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -53.085 -13.547  -3.851   9.538 144.487 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 183.54338    3.24339   56.59   &lt;2e-16 ***
## HT           -0.37869    0.02006  -18.87   &lt;2e-16 ***
## SEXM          8.30226    0.40559   20.47   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19.85 on 17485 degrees of freedom
## Multiple R-squared:  0.026,  Adjusted R-squared:  0.02589 
## F-statistic: 233.4 on 2 and 17485 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We see that the relationship between height and SBP remains negative. Specifically, for every extra centimeter of height, we expect SBP to go down by 0.379 mmHG. Sex confounds the relationship between height and blood pressure. We can also note that the coefficient for Sex is a little over 8, meaning that on average, men have a SBP 8 mmHG higher than women.</p>
<p>Hmm, what are we forgetting…? Model diagnostics!</p>
</div>
<div id="assessing-model-adequacy" class="section level3" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Assessing model adequacy</h3>
<p>We have just done a theory-based test but we have not assessed whether the validity conditions are met. The validity conditions for multiple regression are analogous to those for simple regression.
1. Independence; once I have accounted for everything in the model, the responses can be considered independent of each other.
2. The model is linear; when plotting the residuals vs predicted values, there does not appear to be a pattern.
3. The residuals have constant variance; when plotting the residuals vs predicted values, there is a constant width.
4. Normality; a histogram of the residuals is approximately normal.</p>
<p>In practice, it is difficult to check for independence in the data. Unless there is a specific pattern to the way the data was collected, violations of this assumption may not be evident in our residual plots. The best way to verify this assumption is to know how the data was collected. Is it reasonable to consider it a random sample? If, for instance, we had repeated measurements on the same people, this assumption may not be reasonable. One way to check is to plot the residuals in the order they appear in your data. But if the dependence is not related to the order the data was stored, issues may not be visible in this plot.</p>
<p>To check for linearity, we look at the residuals vs fitted values plot. Here we are looking for any pattern in the residuals. They should be scattered roughly evenly above and below the <span class="math inline">\(y=0\)</span> line across the entire graph. (To check more rigorously in multiple regression we would actually check each explanatory variable individually using something called a partial residual plot or component plus residual plot. That is beyond the scope of this course.)</p>
<p>To check for constant variance, we again look at the residuals vs predicted values. We are checking to see if the variability in the residuals is approximately the same for different values of the response. A widening of our residuals as y_hat increases, for instance, would indicate this assumption is not met.</p>
<p>Finally, to check for normality, we look at a histogram of the residuals to see if it looks at least approximately normal.</p>
<p>For our blood pressure example, we only have one observation on each person and we have a pseudo-random sample of the U.S. (Details on the exact sampling plan can be found on the CDC’s NHANES website.) Additionally, if we plot the residuals vs their index (i.e. in the order they are in the data) we see no clear pattern to the residuals. It seems reasonable that our independence validity condition is met.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="confounding-adjustment-with-regression.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(ht_gen_mod<span class="sc">$</span>residuals),ht_gen_mod<span class="sc">$</span>residuals)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The following figure depicts the residuals vs fitted values from our model with both height and Sex. The residuals do not show a pattern and are scattered roughly equally above and below the <span class="math inline">\(y = 0\)</span> line. It seems reasonable to believe that the linearity validity condition is met.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="confounding-adjustment-with-regression.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ht_gen_mod<span class="sc">$</span>fitted,ht_gen_mod<span class="sc">$</span>residuals)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>From this same plot, we see the variance of the residuals is relatively constant as our predicted SBP increases. The validity condition requiring equal variance seems reasonable.</p>
<p>The histogram of our residuals looks relatively normal although it does seem to have a heavy right tail. Our residuals may not be strictly normal. However, linear regression is “robust” to departures from normality. That means that slight, or even moderate, departures from normality generally do not pose a problem. Our residuals look “normal enough” that I feel comfortable concluding that our validity conditions are met.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="confounding-adjustment-with-regression.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(ht_gen_mod<span class="sc">$</span>resid)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>What would we expect to see if the validity conditions were violated? Below are some examples of model diagnostic plots that indicate a departure from our validity conditions. We simulated the data used to create these plots so we know which conditions are not valid. These are also relatively extreme examples for illustrative purposes; in real data you often will not see patterns this obvious. Violations of our model’s validity conditions can be especially hard to detect when we have a small sample size.</p>
<p>First, we look at independence. The following plot of residuals in order show a clear pattern. The residuals seem to be in triplets; first we have a positive residual, then a residual around zero, then a negative residual. This pattern indicates that are model is missing an important factor, like time. Perhaps the data was a reading collected three times a day - morning, noon and night - and we expect the reading will differ based on time of day but we did not include that in the model. Departures from independence are rarely this easy to spot.</p>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<!--When we include the *time* variable in the model, we see that the pattern disappears. [I think maybe I leave this part out?]

<img src="MA206supplement_files/figure-html/unnamed-chunk-11-1.png" width="672" />
-->
<p>Next we look at the linearity assumption. Below we see a residuals vs fitted values plot that shows a clear pattern. Fitted values below about 150 or above about 350 tend to have positive residuals (i.e. be underestimated) whereas fitted values between 150 and 350 tend to have negative residuals (i.e. be overestimated). This is an indication that our linearity assumption is violated; the right hand side of the model is not correctly specified.</p>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<!--In fact, here $Y$ was a function of $X^2$, not $X$.  When we add $X^2$ to the model, we again see that the probelm disappears.

<img src="MA206supplement_files/figure-html/unnamed-chunk-13-1.png" width="672" />
-->
<p>Next we investigate our assumption of constant variance. In the plot below, we see a clear fanning out of the residuals; as <span class="math inline">\(\hat{y}\)</span> increases, the variance of the residuals decreases.</p>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>And finally, we investigate our normality assumption. In the plot below, we see that are residuals are heavily skewed to the right. The assumption of normality is violated.</p>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>In our example, researchers were specifically interested in the relationship between height and blood pressure so height was our treatment variable. Sex was related to both height and blood pressure so we need to include it in our model, but we are not particularly interested in the relationship between Sex and blood pressure from a clinical or scientific standpoint. So Sex was a confounding variable. Notice that we treat these variables the same from a statistical standpoint. It is possible to have multiple exposures or treatments, multiple confounders, or both. The distinction between the two is not a statistical one; it is a scientific one.<br />
<!--[Note about prediction.]--></p>
</div>
</div>
<div id="quantitative-explanatory-variable-with-quantitative-confounding-variable" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Quantitative explanatory variable with quantitative confounding variable</h2>
<p>Confounding variables can, of course, be quantitative as well. Here we will explore the situation where you have a quantitative treatment variable <span class="math inline">\((X)\)</span>, a quantitative response variable <span class="math inline">\((Y)\)</span>, and a quantitative confounding variable <span class="math inline">\((C)\)</span>. In fact, the ice cream example from the chapter 4 was just such a situation.</p>
<div id="unadjusted-effect-of-x-on-y-1" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Unadjusted effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span></h3>
<p>The file wage_data.csv on the course website contains a subset of wage data from the Center for Economic and Policy Research. It includes individual annual income from wages and salary (Earnings) for people who are above the poverty line<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> but below the “top 2%”<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>.We wish to explore the relationship between family size and earnings. A scatterplot indicates that there does appear to be a positive relationship between the two variables.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="confounding-adjustment-with-regression.html#cb10-1" aria-hidden="true" tabindex="-1"></a>wage_dat<span class="ot">&lt;-</span><span class="fu">read_csv</span>(<span class="st">&quot;wage_data.csv&quot;</span>)</span></code></pre></div>
<pre><code>## Rows: 500 Columns: 20</code></pre>
<pre><code>## -- Column specification --------------------------------------------------------
## Delimiter: &quot;,&quot;
## chr  (5): Education, Sex, MaritalStatus, Race, FamilyMakeup
## dbl (15): X1, educ92, occly2d_03, female, incp_wag, age, marstat, empl, wbha...</code></pre>
<pre><code>## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="confounding-adjustment-with-regression.html#cb14-1" aria-hidden="true" tabindex="-1"></a>wage_dat<span class="sc">%&gt;%</span></span>
<span id="cb14-2"><a href="confounding-adjustment-with-regression.html#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>FamilySize, <span class="at">y=</span>Earnings))<span class="sc">+</span></span>
<span id="cb14-3"><a href="confounding-adjustment-with-regression.html#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb14-4"><a href="confounding-adjustment-with-regression.html#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;Family Size&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Annual Earnings&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Family Size versus Annual Earnings&quot;</span>)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>If we were to consider only the treatment variable FamilySize and the response variable Earnings, we could use the following regression equation:
<span class="math display">\[\widehat{Earnings} = \beta_0+\beta_1*FamilySize\]</span>
Fitting this in R, we get the following results:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="confounding-adjustment-with-regression.html#cb15-1" aria-hidden="true" tabindex="-1"></a>size_mod <span class="ot">=</span> <span class="fu">lm</span>(Earnings<span class="sc">~</span>FamilySize, <span class="at">data =</span> wage_dat)</span>
<span id="cb15-2"><a href="confounding-adjustment-with-regression.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(size_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Earnings ~ FamilySize, data = wage_dat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -41825 -28222 -13021  13383 141580 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    49013       4212  11.636  &lt; 2e-16 ***
## FamilySize      4802       1272   3.775 0.000179 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 39120 on 498 degrees of freedom
## Multiple R-squared:  0.02782,    Adjusted R-squared:  0.02587 
## F-statistic: 14.25 on 1 and 498 DF,  p-value: 0.0001792</code></pre>
<p>We see that there is a very significant effect of family size on earnings; for every additional member of the family, we expect to earn about $4802 more.</p>
</div>
<div id="effect-of-x-on-y-adjusting-for-c-1" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> adjusting for <span class="math inline">\(C\)</span></h3>
<p>However, there are a number of factors that are related to both earnings and family size, perhaps in a causal way. We will look at age. We expect to earn more as we age and get more experience in the workforce and possibly even more education. We also expect that, in general, family size will increase - or at least stay the same - as we get older. We can visually inspect our data to check this. Below is a graph of earnings versus age.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="confounding-adjustment-with-regression.html#cb17-1" aria-hidden="true" tabindex="-1"></a>wage_dat<span class="sc">%&gt;%</span></span>
<span id="cb17-2"><a href="confounding-adjustment-with-regression.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="st">`</span><span class="at">Age</span><span class="st">`</span>,</span>
<span id="cb17-3"><a href="confounding-adjustment-with-regression.html#cb17-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">y=</span><span class="st">`</span><span class="at">Earnings</span><span class="st">`</span>))<span class="sc">+</span></span>
<span id="cb17-4"><a href="confounding-adjustment-with-regression.html#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb17-5"><a href="confounding-adjustment-with-regression.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se=</span><span class="cn">FALSE</span>)<span class="sc">+</span></span>
<span id="cb17-6"><a href="confounding-adjustment-with-regression.html#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>()</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Age is a potential <em>confounder</em>. When we add age to the model with family size, we have the following regression model:</p>
<p><span class="math display">\[\widehat{Earnings}=\beta_0+\beta_1*FamilySize+\beta_2*Age\]</span>
When we estimate the coefficents for this model in R, we get the following results.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="confounding-adjustment-with-regression.html#cb19-1" aria-hidden="true" tabindex="-1"></a>size_age_mod <span class="ot">=</span> <span class="fu">lm</span>(Earnings<span class="sc">~</span>FamilySize<span class="sc">+</span>Age, <span class="at">data =</span> wage_dat)</span>
<span id="cb19-2"><a href="confounding-adjustment-with-regression.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(size_age_mod)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Earnings ~ FamilySize + Age, data = wage_dat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -48975 -26711 -12103  14107 145564 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  26643.8     8322.0   3.202  0.00145 ** 
## FamilySize    5534.1     1283.0   4.314 1.94e-05 ***
## Age            449.7      144.7   3.107  0.00199 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 38790 on 497 degrees of freedom
## Multiple R-squared:  0.04635,    Adjusted R-squared:  0.04251 
## F-statistic: 12.08 on 2 and 497 DF,  p-value: 7.551e-06</code></pre>
<p>We see that there is still a significant positive effect of family size on earnings, although it’s magnitude is slightly larger. We expect to earn about $5534 more per year for every additional member of the family <em>after adjusting for age</em>. We also note that the coefficient for age is 449.7, meaning that, for every year older a person is, we expect them to earn $450 more on average, after adjusting for family size. Of course, the relationship between family size and earnings is a complex one that would require a much more extensive analysis to fully understand.</p>
</div>
<div id="assessing-model-adequacy-1" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Assessing model adequacy</h3>
<p>Just like with previous regression models, these results might not mean much if our validity conditions aren’t met.</p>
<p>Here, we may be willing to believe that our assumption of independence is met by the way the data was collected. The CEPR data is from the Current Population Survey’s Annual Social and Economic Supplement (CPS ASEC or March Supplement). Surveyors use a random sample to survey about 60,000 occupied households by both telephone and in person surveys. Households come from all 50 states and the District of Columbia and are only in the sample pool for a limited time. Since respondents responses to survey questions are not dependent on another respondents, independence can be assumed.</p>
<p>To check for linearity and equal variance, we can plot the predicted values vs. the residuals.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="confounding-adjustment-with-regression.html#cb21-1" aria-hidden="true" tabindex="-1"></a>size_age_mod<span class="sc">%&gt;%</span></span>
<span id="cb21-2"><a href="confounding-adjustment-with-regression.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fortify</span>(wage_dat)<span class="sc">%&gt;%</span></span>
<span id="cb21-3"><a href="confounding-adjustment-with-regression.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .resid))<span class="sc">+</span></span>
<span id="cb21-4"><a href="confounding-adjustment-with-regression.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb21-5"><a href="confounding-adjustment-with-regression.html#cb21-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>)<span class="sc">+</span></span>
<span id="cb21-6"><a href="confounding-adjustment-with-regression.html#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>( <span class="at">x =</span> <span class="st">&quot;Predicted Values&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Residuals&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Residuals vs. predicted values&quot;</span>)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>The linearity and constant variance conditions appear to be met. Although we have some large positive residuals, there does not appear to be a pattern and the width is relatively constant.</p>
<p>Our histogram, however, shows that the residuals seem to be skewed relatively heavily to the right. Our fourth validity condition, normality of the residuals, is likely not met. Although we can be comfortable in our estimates of the regression coefficients, we should be careful about drawing any conclusions about their statistical significance. (For a much more in depth assumption about assessing model adequacy, to include methods to handle violations of the validity conditions, take MA376!)</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="confounding-adjustment-with-regression.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(size_age_mod<span class="sc">$</span>residuals)</span></code></pre></div>
<p><img src="MA206supplement_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><a href="https://aspe.hhs.gov/2021-poverty-guidelines#threshholds" class="uri">https://aspe.hhs.gov/2021-poverty-guidelines#threshholds</a><a href="confounding-adjustment-with-regression.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="https://www.businessinsider.com/top-two-percent-every-us-state-2017-7" class="uri">https://www.businessinsider.com/top-two-percent-every-us-state-2017-7</a><a href="confounding-adjustment-with-regression.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="causality.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interactions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MA206supplement.pdf", "MA206supplement.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
